# Run all benchmarks when a comment containing "test performance please"
#Â comment is posted on a PR.

name: Benchmarks Matrix

on:
  issue_comment:
    types: [created]
  workflow_dispatch:
    inputs:
      commit:
        description: "Commit to benchmark."
        required: true
        type: string
      repo:
        description: "GitHub repository containing the commit to benchmark."
        required: true
        type: string
        default: "mbovel/dotty" # TODO(mbovel): Change to scala/scala3
      runs:
        description: "Number of runs to perform."
        required: true
        type: number
        default: 1
      profile_set:
        description: "Profile to run: 'merge' to run the benchmarks that are run on every PR merge (shorter), 'nightly' to run nightly benchmarks (longer), or 'all' to run both."
        required: true
        type: choice
        options:
          - merge
          - nightly
          - all

permissions:
  contents: read
  pull-requests: write # Needed to post comments on PRs

jobs:
  start_comment:
    name: Start comment
    if: github.event.issue.pull_request && contains(github.event.comment.body, 'test performance please')
    runs-on: ubuntu-latest
    steps:
      - name: Comment
        uses: actions/github-script@v7
        with:
          script: |
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              body: `Thanks for your request. Your benchmarks will be run shortly.\nYou can follow the progress at https://github.com/mbovel/dotty/actions/runs/${context.runId}.`
            })

  generate_runs:
    name: Generate run definitions
    runs-on: ["self-hosted", "benchmarks"]
    steps:
      - id: generate_runs
        uses: actions/github-script@v7
        with:
          script: | #js
            const fs = require('fs');

            let commits, run_indices, profile_set;
            switch (context.eventName) {
              case 'issue_comment':
                const { data } = await github.rest.pulls.get({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  pull_number: context.payload.issue.number
                });

                // Base is the last commit on the base branch, head is the last
                // commit on the PR branch. Run benchmarks on both.
                commits = [
                  { commit: data.base.sha, repo: data.base.repo.full_name },
                  { commit: data.head.sha, repo: data.head.repo.full_name }
                ];

                const runs_match = context.payload.comment.body.match(/(\d+) runs/);
                const n_runs = runs_match ? parseInt(runs_match[1]) : 1;
                run_indices = Array.from({ length: n_runs }, (_, i) => i); // [0, ..., n_runs - 1]

                profile_set = context.payload.comment.body.includes('all') ? 'all' : 'merge';
                break;

              case 'workflow_dispatch':
                commits = [{ commit: context.payload.inputs.commit, repo: context.payload.inputs.repo }];
                run_indices = Array.from({ length: context.payload.inputs.runs }, (_, i) => i);
                profile_set = context.payload.inputs.profile_set;
                break;

              default:
                throw new Error(`Unsupported event: ${context.eventName}`);
            }

            const profiles = profile_set === 'all' ? ['merge', 'nightly'] : [profile_set];
            const runs = [];
            for (const run_index of run_indices) {
              for (const commit of commits) {
                for (const profile of profiles) {
                  console.log(`Scheduling run ${run_index} for commit ${commit.commit} with profile ${profile}.`);
                  runs.push({
                    commit: commit.commit,
                    repo: commit.repo,
                    index: run_index,
                    profile: profile
                  });
                }
              }
            }

            core.setOutput('runs', JSON.stringify(runs));
            core.setOutput('visualizer_url', `https://dotty-bench.epfl.ch/v3/compare.html#${commits.map(c => c.commit).join(',')}`);
    outputs:
      runs: ${{steps.generate_runs.outputs.runs}}
      visualizer_url: ${{steps.generate_runs.outputs.visualizer_url}}

  run:
    name: Run
    needs: ["generate_runs"]
    strategy:
      matrix:
        run: ${{fromJson(needs.generate_runs.outputs.runs)}}
      max-parallel: 1
    uses: ./.github/workflows/bench.yml
    with:
      commit: ${{matrix.run.commit}}
      repo: ${{matrix.run.repo}}
      run: ${{matrix.run.index}}
      profile: ${{matrix.run.profile}}

  end_comment:
    name: End comment
    needs: ["run"]
    if: (failure() || success()) && github.event_name == 'issue_comment'
    runs-on: ubuntu-latest
    steps:
      - name: Comment
        uses: actions/github-script@v7
        with:
          script: |
            console.log(context.payload)
            const body =
              ${{steps.run.outcome == 'success'}}
                ? `Your benchmarks have been run. You can see the results at ${{needs.generate_runs.outputs.visualizer_url}}.`
                : 'An error unfortunately occurred while running your benchmarks.\n@mbovel please take a look.';
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              body: body
            });
